# Google-Advanced-Data-Analytics-Tik-Tok-Project
This is my completion of the TikTok guided project offered by the Google Advanced Data Analytics Certificate. Within this project, there are different components which follow the data analytics process: Exploratory Data Analysis, Data Cleaning and Transformation, creating Visualizations, Hypothesis Testing, Linear and Logistic Regression, and some Machine Learning.

The 1st coding portion of the project, **TikTok-Project-Understanding-the-data**, is where I gained my initial experience with the standard operational packages: pandas and numpy. I used them to filter and display the data (still in table form). I was able to familiarize myself with masking and groupby to separate the data as needed.

The 2nd portion of the project, **TikTok-Project-EDA-Cleaning-Visualizations**, focused majorly on visualizations. I was introduced to some commonly used visualization packages: matplotlib and seaborn and with those two packages I created a variety of graphs and charts to create deeper insight for the dataset I was working with. There was also some data cleaning steps involved to handle missing data.

The 3rd portion of the project, **TikTok-Project-Hypothesis-Testing**, applied some of the statistical concepts required to determine the statistical significance of variables and their impact. In the course associated with this portion of the project, I learned about confidence level, p-value, null-hypothesis, Type I and II errors, z-score (which leads into z-tests), and t-tests. The project itself applied a two-sample t-test to check if a variable "video_view_count" was affected by the binary categorical variable "verified_status". Because there are two independent groups and we are comparing their "video_view_count" which was not a normal distribution.

The 4th portion of the project, **Tiktok-Project-Logistic-Regression**, and its respective course was where I was introduced to the basicis of linear and logistic regression. Regarding linear regression, I learned about the 4 assumptions that would make a linear regression model appropriate for the situation: Linearity, Normality, Independence, and Homoscedasticity. I also learned the commonly used performance-related metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE), R-squared, and Mean Absolute Percentage Error (MAPE). Regarding logistic regression (which is also what the project fell under), I learned about the ROC curve and AUC (Area Under Curve metric to describe performance of a logistic regression model) as well as True Positives, False Positives, True Negatives, False Negatives. The course only delved into logistic regression for the case of binary categorical variables. Data preprocessing was necessary to prepare the features for the model. I was introduced to the correlation matrix as an aide for variable selection and warnings of overfitting the model if too many were selected and underfitting if too little are selected or if the model is inappropriate. After the model was trained and predicted on the test set, model performance review tools like the confusion matrix and the Accuracy, Precision, Recall, and F1 Score metrics allowed me to understand the results of my model.

The 5th portion of the project **TikTok-Project-RandomForest-XGBoost-Machine-Learning**, 
